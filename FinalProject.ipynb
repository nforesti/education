{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the continued push for a more educated society, the demand for college degrees in order to obtain a middle-income job has dramatically increased. This need for additional education, after receiving one’s high school diploma, has drastically changed the college enrollment rate. We can see this in the increasing percentage of enrollments from, “35 percent in 2000 to 41 percent in 2016” (NCES).  Due to this increase, the struggle to attend a top-tier university in the United States has only become more difficult due to the rise in college applications per university. As a result, only students whose resumes depict an exceptional, well-versed student, including a plethora of extra-curriculars in addition to top notch grades, make the cut for these top universities and colleges in the United States. \n",
    "\n",
    "Now with the dramatic rise of financial aid, the strive and responsibility for the United States to make all opportunities equal, and the desire for a more diverse college population, our group is curious as to how the racial demographic in both top-tier and bottom colleges compare to the racial demographics of the city in which the university is placed in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Neve Foresti (data cleaning, analysis & results 1)\n",
    "- Emily Chou (data wrangling, data cleaning, analysis & results 1)\n",
    "- Sahba Mobini Farahani (ethics & privacy, analysis & results 2)\n",
    "- Belen Romero (data exploration, conclusion, background)\n",
    "- Marie Paris (overview, background, analysis & results 2, conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members IDs\n",
    "\n",
    "- A15024369\n",
    "- A12845123\n",
    "- A13510656\n",
    "- A12848386\n",
    "- A13451571\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the racial demographic data of universities compare with the racial demographic data of the city in which the colleges are located?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been some data to show that college ready, high-school students are continuously applying to schools that are near metropolitan cities because of the desire of excitement expected in a major city. Thus, top-tier educational institutions are conveniently located close to, or are neighboring, major metropolitan cities, such as New York or Boston. In other cases, top ranked institutions are located in what are now coming to be known as “university cities.” These college towns are a new breed of city that stands apart from the usual hustle and bustle of that we are accustomed to seeing. \n",
    "\n",
    "Instead, these cities present with a myriad of interesting attributes. They are a unique urban environment which consists of low crime rates, high population education level, and increased participation within the arts. These are population dense envornments that we would expect to see in major ciites, yet they are are characteristically closer to a suburban environment. That leads us to the question of racial demographics. With this new breed of city on the rise, we can start to take a closer look at what kind of environment the average college student is living and learning in. An traditional metropolitan city will usually have a large amount of diversity, while a University City would not. This leads to the interest in how the racial gap between the university’s racial demographic and the city surrounding the school can play into the change of the city based on the racial make-up of the college in that area.\n",
    "\n",
    "In our exploration we looked at the national level for differences between college students and the racial demographic of all people in the United States. When looking at multiple forms of census data, we can already see the variety in the types of breakdowns of Race and Ethnicity that are the most common. US Census data has a very limited amount of racial and ethnic breakdown. Then Census only officially acknowledges Non-Hispanic and Hispanic as ethnicities in their data. There are also a limited number of Races that the Census considers in their data. Since the US Census is typically the most accurate dataset in the United States, we will likely be facing issues similar to these when using any dataset involving demographics, unless we use data from a separate source.\n",
    "\n",
    "There is also the issue of age range when looking at the publicly available datasets involving personal data. The most obvious issue is that data is generalized into percentages or trends/trend changes. This can be due to a couple of different reasons such as keeping information private. The US Census does allow researchers to access their data after if needed and approved for use in their research, but it is not information that is easily given out. This does mean that there usually are not ways to combine 2 variables since the Census Bureau does not provide this information, and also. This does mean that we would be unable to create an accurate portrayal of the differences between the people who are in college and all college-aged people in the United States.\n",
    "\n",
    "References:\n",
    "- 1) https://nces.ed.gov/programs/coe/pdf/coe_cpb.pdf\n",
    "- 2) https://www.insidehighered.com/news/2017/05/04/author-discusses-new-book-relationships-including-tensions-over-race-and-economics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis for Analysis One: Top ranked universities often attract students from all over the country who vie for admission to these schools. Famous colleges are also under more pressure to admit a diverse range of students in terms of racial demographics. Lower ranked universities tend to have more local students who often pay lower admission fees or are not looking to attend schools outside of their county. Thus, we hypothesize that lower ranked schools will have higher racial demographic similarity with the surrounding county than higher ranked schools.\n",
    "\n",
    "Hypothesis for Analysis Two: Larger unviersities represent a more diverse student body compared to smaller universities. We predict the top tier of undergraduate population are more diverse because bigger universities pull more student applications and therefore are exposed to a more pool of potential students. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Census Data\n",
    "- Dataset Name: U.S. Census Bureau\n",
    "- Link to the dataset: https://www.census.gov/quickfacts\n",
    "- Number of observations: all law abiding U.S. citizens over 18 in specified area/63 categories for each city and county/10 cities/10 counties\n",
    "\n",
    "This dataset provides varying information on specific cities and counties such as racial demographics and population. \n",
    "\n",
    "### 2. Niche College Data\n",
    "- Dataset Name: Niche.com 4-Year Best Colleges\n",
    "- Link to the dataset: https://www.niche.com/colleges/search/best-colleges/\n",
    "- Number of observations: 880\n",
    "\n",
    "This website provides information related to all ranked (880) 4-year public and private colleges in the United States. We will be scraping undergraduate population and racial demographic data from this website.\n",
    "\n",
    "### Combining the data:\n",
    "The census data will be used in tandem with the college dataset in order to compare the relationships between racial demographic data of colleges and the counties they are located in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb #to run this you will need to type into your terminal: pip install import-ipynb\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data on cities and counties were sourced from https://www.census.gov/quickfacts.\n",
    "\n",
    "Because we will be analyzing the impact, if any, of variously ranked colleges on the respective cities and counties they are located in, we want the data to be organized based on ranking, allowing us to easily isolate the analysis.\n",
    "\n",
    "The U.S. Census Bureau provides us tables with the following data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_dataset_path = './datasets/cities/'\n",
    "counties_dataset_path = './datasets/counties/'\n",
    "\n",
    "# create separate dictionaries for each category of colleges that the cities are home to\n",
    "top_cities = dict()\n",
    "mid_cities = dict()\n",
    "bot_cities = dict()\n",
    "other_cities = dict() # misc areas for further analysis\n",
    "\n",
    "# populate dicts based on filename indicators\n",
    "for c in os.listdir(cities_dataset_path):\n",
    "    # filenames truncated to city-state format for simplicity\n",
    "    truncated_file_name = '-'.join((c.split('-')[:2]))\n",
    "    if c.endswith(\"top-city.csv\"):\n",
    "        top_cities[truncated_file_name] = pd.read_csv(cities_dataset_path + c)\n",
    "    elif c.endswith(\"mid-city.csv\"):\n",
    "        mid_cities[truncated_file_name] = pd.read_csv(cities_dataset_path + c)\n",
    "    elif c.endswith(\"bot-city.csv\"):\n",
    "        bot_cities[truncated_file_name] = pd.read_csv(cities_dataset_path + c)\n",
    "    elif '-' in c:\n",
    "        other_cities[truncated_file_name] = pd.read_csv(cities_dataset_path + c)\n",
    "\n",
    "# similar process for counties\n",
    "top_counties = dict()\n",
    "mid_counties = dict()\n",
    "bot_counties = dict()\n",
    "other_counties = dict()\n",
    "\n",
    "for c in os.listdir(counties_dataset_path):\n",
    "    # filenames truncated to county-state format for simplicity\n",
    "    truncated_file_name = '-'.join((c.split('-')[:2]))\n",
    "    if c.endswith(\"top-county.csv\"):\n",
    "        top_counties[truncated_file_name] = pd.read_csv(counties_dataset_path + c)\n",
    "    elif c.endswith(\"mid-county.csv\"):\n",
    "        mid_counties[truncated_file_name] = pd.read_csv(counties_dataset_path + c)\n",
    "    elif c.endswith(\"bot-county.csv\"):\n",
    "        bot_counties[truncated_file_name] = pd.read_csv(counties_dataset_path + c)\n",
    "    elif '-' in c:\n",
    "        other_counties[truncated_file_name] = pd.read_csv(counties_dataset_path + c)\n",
    "\n",
    "# testing\n",
    "print('============== TOP TEST ===============')\n",
    "print(top_cities['stanford-ca'])\n",
    "print('\\n============== MID TEST ===============')\n",
    "print(mid_cities['whitewater-wi'])\n",
    "print('\\n============== BOT TEST ===============')\n",
    "print(bot_counties['westmoreland-pa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing County & City Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv = [top_cities, mid_cities, bot_cities, other_cities, top_counties, mid_counties, bot_counties, other_counties]\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        v.rename(index = str, columns = {v.columns[2] : 'Fact Value'}, inplace = True)\n",
    "\n",
    "assert top_cities['cambridge-ma'].columns[2] == 'Fact Value'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the column that should hold the fact value is of type object (str). We want this to be converted to ints so that we do not need to constantly type cast when performing our analysis.\n",
    "\n",
    "To do this, we need to first delete rows that a fact value that indicates this statistic is not useful such as NA for not available. Further descriptions of the invalid value strings are given in a following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(bot_cities['redding-ca'].loc[bot_cities['redding-ca']['Fact Value'] == 'X']) != 0\n",
    "invalid_values = ['X', 'NA', 'D', '-', 'FN', 'F', 'S', 'Z']\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        for i, r in v.iterrows():\n",
    "            if r['Fact Value'] in invalid_values:\n",
    "                v.drop(i, inplace = True)\n",
    "                \n",
    "\n",
    "assert len(bot_cities['redding-ca'].loc[bot_cities['redding-ca']['Fact Value'] == 'X']) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can iterate through the Fact Value column, strip all non-numeric or . (indicating a decimal number) characters and retype each value from str to float64. We print out the pre and post cleaning types of the Fact Value column to verify our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before cleaning:')\n",
    "print(mid_counties['walworth-wi']['Fact Value'].dtypes)\n",
    "\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        v.loc[:, 'Fact Value'] = v.loc[:, 'Fact Value'].str.strip('%\"$')\n",
    "        v.loc[:, 'Fact Value'] = v.loc[:, 'Fact Value'].str.replace(',', '')   \n",
    "        v.loc[:, 'Fact Value'] = v.loc[:, 'Fact Value'].astype('float64')\n",
    "        \n",
    "print('\\nAfter cleaning:')\n",
    "print(mid_counties['walworth-wi']['Fact Value'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the initial output of our data wrangling, there are a couple of entirely or largely unneeded *columns* in the data where all the values are either NaN or irrelevant. \n",
    "\n",
    "We will be dropping or modifying the following columns to clean the data:\n",
    "\n",
    "###### Fact Note:\n",
    "\n",
    "This indicates:\n",
    "\n",
    "**(a)** Includes persons reporting only one race\n",
    "\n",
    "**(b)** Hispanics may be of any race, so also are included in applicable race categories\n",
    "\n",
    "**(c)** Economic Census - Puerto Rico data are not comparable to U.S. Economic Census Data\n",
    "\n",
    "As none of these factors influence the demographic data of the areas we are analyzing, we can remove this data.\n",
    "\n",
    "###### Value Note \n",
    "\n",
    "This indicates: \n",
    "\n",
    "**(-)** Either no or too few sample observations were available to compute an estimate, or a ratio of medians cannot be calculated because one or both of the median estimates falls in the lowest or upper interval of an open ended distribution.\t\n",
    "\n",
    "**(D)**\tSuppressed to avoid disclosure of confidential information\t\n",
    "\n",
    "**(F)**\tFewer than 25 firms\t\t\n",
    "\n",
    "**(FN)** Footnote on this item in place of data\t\n",
    "\n",
    "**(NA)** Not available\t\t\n",
    "\n",
    "**(S)**\tSuppressed; does not meet publication standards\n",
    "\n",
    "**(X)**\tNot applicable\n",
    "\n",
    "**(Z)**\tValue greater than zero but less than half unit of measure shown\n",
    "\n",
    "Value notes are indicated in the Fact Value column so we do not need the Value Note column at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert top_cities['stanford-ca'].shape == (67, 4)\n",
    "\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        v.drop([v.columns[1], v.columns[3]], axis = 1, inplace = True)\n",
    "\n",
    "assert top_cities['stanford-ca'].shape == (67, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also observe that there are also many *rows* that have a NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = 0\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        nan_count += v['Fact'].isna().sum()\n",
    "        nan_count += v['Fact Value'].isna().sum()\n",
    "\n",
    "print('Total number of NaN values: ' + str(nan_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These NaN rows are not useful, so we will drop these rows entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = 0\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        v.dropna(inplace = True)\n",
    "        nan_count += v['Fact'].isna().sum()\n",
    "        nan_count += v['Fact Value'].isna().sum()\n",
    "\n",
    "print('Total number of NaN values: ' + str(nan_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our analysis will only need statistics about demographics, we can drop all rows with irrelevant statistics. We decided to do this last so that, in case we do need to use other statistics, the data for that row will already be cleaned up to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_rows = ['White alone, percent', 'Black or African American alone, percent', 'American Indian and Alaska Native alone, percent', 'Asian alone, percent', 'Native Hawaiian and Other Pacific Islander alone, percent', 'Two or More Races, percent', 'Hispanic or Latino, percent', 'White alone, not Hispanic or Latino, percent']\n",
    "\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        d[k] = v.loc[(v['Fact'].isin(demographic_rows))]\n",
    "        # reset index to start from 0 since rows before may have been dropped\n",
    "        d[k].reset_index(drop = True, inplace = True)\n",
    "\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        assert d[k].shape == (7, 2) or d[k].shape == (8, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now left with dataframes that are of shape either (7, 2) or (8, 2), have no NaN values, have values that are ready to analyze and work with (float type) and only contain relevant demographic statistics.\n",
    "\n",
    "#### Here is the final cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        print(k + ' | shape: ' + str(v.shape))\n",
    "        print(v)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's convert the data from dictionaries to dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder cities dictionaries to correspond with rankings\n",
    "\n",
    "order_top_cities = OrderedDict()\n",
    "order_top_cities['cambridge-ma'] = top_cities['cambridge-ma']\n",
    "order_top_cities['stanford-ca'] = top_cities['stanford-ca']\n",
    "order_top_cities['newhaven-ct'] = top_cities['newhaven-ct']\n",
    "top_cities = order_top_cities\n",
    "\n",
    "order_mid_cities = OrderedDict()\n",
    "order_mid_cities['westerville-oh'] = mid_cities['westerville-oh']\n",
    "order_mid_cities['whitewater-wi'] = mid_cities['whitewater-wi']\n",
    "order_mid_cities['jacksonville-il'] = mid_cities['jacksonville-il']\n",
    "mid_cities = order_mid_cities\n",
    "\n",
    "order_bot_cities = OrderedDict()\n",
    "order_bot_cities['greensburg-pa'] = bot_cities['greensburg-pa']\n",
    "order_bot_cities['sanbernardino-ca'] = bot_cities['sanbernardino-ca']\n",
    "order_bot_cities['redding-ca'] = bot_cities['redding-ca']\n",
    "bot_cities = order_bot_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all city csv to dataframe\n",
    "columns = demographic_rows\n",
    "\n",
    "df_cities = pd.DataFrame()\n",
    "i1 = 0\n",
    "city_csv = [top_cities, mid_cities, bot_cities, other_cities]\n",
    "for a in city_csv:\n",
    "    index = 0\n",
    "    for b in a.keys():\n",
    "        i2 = 0\n",
    "        for x in range(0, 8):\n",
    "            if x < len(city_csv[i1].get(b)[\"Fact Value\"]):\n",
    "                #if a value is not present (always pacific islander data), we set it equal to zero\n",
    "                if (len(city_csv[i1].get(b)[\"Fact Value\"]) < 7) and x ==4:\n",
    "                     df_cities.loc[x,b] = 0\n",
    "                else:\n",
    "                    df_cities.loc[x,b] = (city_csv[i1].get(b)[\"Fact Value\"][i2])\n",
    "            i2 = i2 + 1\n",
    "    i1 = i1 + 1\n",
    "    index = index + 1\n",
    "df_cities = df_cities.transpose()\n",
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder county dictionaries to correspond with rankings\n",
    "\n",
    "order_top_counties = OrderedDict()\n",
    "order_top_counties['middlesex-ma'] = top_counties['middlesex-ma']\n",
    "order_top_counties['santaclara-ca'] = top_counties['santaclara-ca']\n",
    "order_top_counties['newhaven-ct'] = top_counties['newhaven-ct']\n",
    "top_counties = order_top_counties\n",
    "\n",
    "order_mid_counties = OrderedDict()\n",
    "order_mid_counties['delaware-oh'] = mid_counties['delaware-oh']\n",
    "order_mid_counties['walworth-wi'] = mid_counties['walworth-wi']\n",
    "order_mid_counties['morgan-il'] = mid_counties['morgan-il']\n",
    "mid_counties = order_mid_counties\n",
    "\n",
    "order_bot_counties = OrderedDict()\n",
    "order_bot_counties['westmoreland-pa'] = bot_counties['westmoreland-pa']\n",
    "order_bot_counties['sanbernardino-ca'] = bot_counties['sanbernardino-ca']\n",
    "order_bot_counties['shasta-ca'] = bot_counties['shasta-ca']\n",
    "bot_counties = order_bot_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all county csv to dataframe\n",
    "df_counties = pd.DataFrame()\n",
    "i1 = 0\n",
    "county_csv = [top_counties, mid_counties, bot_counties, other_counties]\n",
    "for a in county_csv:\n",
    "    index = 0\n",
    "    for b in a.keys():\n",
    "        bool = False\n",
    "        i2 = 0\n",
    "        for x in range(0, 8):\n",
    "            if len(county_csv[i1].get(b)[\"Fact Value\"]) < 8 and x==4:\n",
    "                bool = True\n",
    "                df_counties.loc[x,b] = 0\n",
    "            elif bool == True:\n",
    "                df_counties.loc[x,b] = (county_csv[i1].get(b)[\"Fact Value\"][i2-1])\n",
    "            else:\n",
    "                df_counties.loc[x,b] = (county_csv[i1].get(b)[\"Fact Value\"][i2])\n",
    "            i2 = i2 + 1\n",
    "    i1 = i1 + 1\n",
    "    index = index + 1\n",
    "df_counties = df_counties.transpose()\n",
    "df_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indexr, city in df_cities.iterrows():\n",
    "    for indexc, newvalue in city.iteritems():\n",
    "        if \".\" in str(newvalue):\n",
    "            oldvalue = (newvalue)\n",
    "            newvalue = (float(newvalue)) / 100\n",
    "            df_cities.loc[indexr,indexc] = round(newvalue, 2)\n",
    "\n",
    "df_cities.columns = [\"White all\", \"African American\", \"Native American\", \"Asian\", \"Pacific Islander\", \"Multiracial\", \"Hispanic\", \"White\"]\n",
    "df_cities['Unknown'] = 1 - df_cities[\"White\"] - df_cities[\"African American\"]-df_cities[\"Native American\"] -df_cities[\"Asian\"]-df_cities[\"Pacific Islander\"] -df_cities[\"Multiracial\"]\n",
    "df_cities = df_cities.drop(\"White all\", axis=1)\n",
    "\n",
    "cols = ['African American', 'Asian', 'Hispanic', 'Multiracial',\n",
    "       'Native American', 'Pacific Islander', 'Unknown', 'White']\n",
    "df_cities = df_cities[cols]\n",
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indexr, county in df_counties.iterrows():\n",
    "    for indexc, newvalue in county.iteritems():\n",
    "        if \".\" in str(newvalue):\n",
    "            oldvalue = (newvalue)\n",
    "            newvalue = (float(newvalue)) / 100\n",
    "            df_counties.loc[indexr,indexc] = round(newvalue, 2)\n",
    "\n",
    "df_counties.columns = [\"White all\", \"African American\", \"Native American\", \"Asian\", \"Pacific Islander\", \"Multiracial\", \"Hispanic\", \"White\"]\n",
    "df_counties['Unknown'] = 1 - df_counties[\"White\"] - df_counties[\"African American\"]-df_counties[\"Native American\"] -df_counties[\"Asian\"]-df_counties[\"Pacific Islander\"] -df_counties[\"Multiracial\"]\n",
    "df_counties = df_counties.drop(\"White all\", axis=1)\n",
    "cols = ['African American', 'Asian', 'Hispanic', 'Multiracial',\n",
    "       'Native American', 'Pacific Islander', 'Unknown', 'White']\n",
    "df_counties = df_counties[cols]\n",
    "df_counties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing University Data\n",
    "\n",
    "First, using the Beautiful Soup package, we created a script to web scrape the 37 pages of ranked public and private [Best Colleges of Niche.com](https://www.niche.com/colleges/search/best-colleges/). \n",
    "For pages 1-37, we sent requests to https://www.niche.com/api/renaissance/results/?type=private&type=public&listURL=best-colleges&page=, which contained information about rankings, names, and links to more information about each of the colleges. For each of these colleges, we then added the unique college link to https://www.niche.com/colleges/. For example, https://www.niche.com/colleges/massachusetts-institute-of-technology/. Lastly, we used Beautiful Soup to extract and print all of the undergraduate population and student racial demographic data to a csv. For the few universities that had missing data, we manually searched the university in Niche.com and entered the demographic data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get racial demographic data\n",
    "df_niche = pd.read_csv(\"datasets/niche4yearpublicprivate.csv\")\n",
    "df_niche.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, there are quite a few things that need to be done. \n",
    "1. All of the values in this dataframe are strings. Hence, we need to convert the demographic data to numeric values. \n",
    "2. The demographic measurements do not match up with the measurements for the city/county census data. Census data does not have an \"international\" category, so in order to compare college with county data, we dropped the International category. We recognize that many of the international students may actually fall into the other categories (and hence result in underrepresenting numbers for some races), but there is no way to know. This is a limitation of how demographic data is collected for colleges, so we will be cautious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check if any null values. If null,manually enter data from niche.com\n",
    "df_niche[df_niche.isnull().any(axis=1)]\n",
    "\n",
    "df_niche = df_niche.drop(\"International\", axis=1)\n",
    "\n",
    "\n",
    "for indexr, university in df_niche.iterrows():\n",
    "    sum = 0\n",
    "    for indexc, newvalue in university.iteritems():\n",
    "        if \"%\" in str(newvalue):\n",
    "            oldvalue = (newvalue)\n",
    "            newvalue = (float(newvalue.rstrip(\"%\"))) / 100\n",
    "            df_niche.loc[indexr,indexc] = newvalue\n",
    "            sum = sum + newvalue #get the sum of all percentages in a row (will not add up to 1.0)\n",
    "    # Here we want to get the proportion of the demographics to each other (after having removed International)\n",
    "    for indexc, newvalue in university.iteritems():\n",
    "        if isinstance(df_niche.loc[indexr,indexc], float):\n",
    "            #find relative proportion of demographics by diving with row total\n",
    "            df_niche.loc[indexr,indexc] = round((float(df_niche.loc[indexr,indexc]) / sum),2)\n",
    "\n",
    "df_800 = df_niche #top 800 #top 800 colleges will be used for analysis 1\n",
    "df_500 = df_niche.head(500) #top 500 colleges will be used for analysis 2\n",
    "df_800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "#### Before going into depth in our Analysis, we will do some minor exploration specifically on the University of California - Berkely, and it's surrounding county, Alameda-CA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = plt.figure(figsize=(15,10))\n",
    "barWidth = 0.30\n",
    "ind = np.arange(8)\n",
    "\n",
    "county = df_counties.loc['alameda-ca'].values\n",
    "univ = (df_800.loc[df_800['name'] == 'university-of-california---berkeley']).drop(columns = ['ranking', 'name'])\n",
    "city = df_cities.loc['berkeley-ca'].values\n",
    "\n",
    "b1 = np.arange(len(county))\n",
    "b2 = b1+barWidth\n",
    "b3 = b2+barWidth\n",
    "\n",
    "plt.bar(b1, county, color='#B22222', width=barWidth, edgecolor='white', label='Alameda County')\n",
    "plt.bar(b2, city, color='#FCE6C9', width=barWidth, edgecolor='white', label='Berkeley')\n",
    "plt.bar(b3, univ.values[0], color='#6495ED', width=barWidth, edgecolor='white', label='UC Berkeley')\n",
    "\n",
    "plt.xlabel('Race', fontweight='bold')\n",
    "plt.ylabel('Proporiton of Total Population', fontweight='bold')\n",
    "plt.xticks(ind + barWidth, df_counties.columns)\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='center')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a glance we can see that the difference in race between these 3 values can seem quite significant. The proportions of White, African American, Asian, and Hispanic suggest that UC Berkeley follows a fairly different trend when compared to the City of Berkeley and Alameda County."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also do a simple linear visualization between the county data and the university data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county = df_counties.loc['alameda-ca']\n",
    "univ = ((df_800.loc[df_800['name'] == 'university-of-california---berkeley']).drop(columns = ['ranking', 'name']).values.astype(float))\n",
    "city = df_cities.loc['berkeley-ca']\n",
    "univ = np.squeeze(univ)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(county, univ, \".\")\n",
    "\n",
    "plt.xlabel('Alameda County');\n",
    "plt.ylabel('UC Berkeley');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.column_stack((county,univ))\n",
    "df = pd.DataFrame(dat, columns=['D1', 'D2'])\n",
    "outcome, predictors = patsy.dmatrices('D2 ~ D1', df)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample size we use is much too small to get valid results, but we can still analyze them for our own purposes. We can check or goodness of fit by looking at the R-Squared and Adjusted R-Squared value we see that we have a fairly strong correlation, so the county data has a somewhat linear relationship with the university data. If one simply look at the values in this test, we can interpret that the results showed a statistically significant difference and that we should reject our null hypothesis. Looking closer, we understand that the sample size is much too small.  \n",
    "\n",
    "As one can see, there doesn't seem to be much that can be gleaned from looking at only these 2 sections of data. The purpose of this exercise was not to get statistically significant evidence, but for us to visualize the small pieces in a way that helps us predict what may be happening in the bigger picture. From the little exploration that has been done, we can move forward in our analysis with a rough understanding of our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 1\n",
    "### For the first part of the analysis, we are interested in looking at how racial demographic data of colleges compares with their surrounding county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot_county_city(county_name, college_name, top_mid_bot, county_color, college_color):\n",
    "    ind = np.arange(8) \n",
    "    width = 0.42\n",
    "\n",
    "    plt.bar(ind, df_counties.loc[county_name].values, width, label = \"\"+county_name+\" (county)\", color = county_color)\n",
    "    df_temp = (df_800.loc[df_800['name'] == college_name]).drop(columns = ['ranking', 'name'])\n",
    "    plt.bar(ind + width, df_temp.values[0], width, label = \"\"+college_name+\" (college)\", color = college_color)\n",
    "\n",
    "    plt.xticks(ind + width / 2, df_counties.columns)\n",
    "    plt.ylabel('Percentage of Total Population')\n",
    "    plt.title('Ethnicity Percentages for ' + top_mid_bot + ' 3 Ranked County & University')\n",
    "    plt.legend(loc='best')\n",
    "    plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following bar graphs, the absence of a bar denotes less than 0 percent of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(18,10))\n",
    "f.suptitle('Graph 1')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "bar_plot_county_city('santaclara-ca', 'stanford-university', 'Top', '#01579b', \"pink\")\n",
    "plt.title(\"Demographics of Stanford with County, Ranked 2\", fontsize = 14)\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Proportion of Population')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "bar_plot_county_city('delaware-oh', 'otterbein-university', 'Middle', '#01579b', 'pink')\n",
    "plt.title(\"Demographics of Otterbein University with County, Ranked 429\", fontsize = 14)\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Proportion of Population')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs above show the possible variation. Stanford, with a high \"Best Colleges\" ranking of 2 clearly has racial demographic data very different from the surrounding county. On the other hand, Otterbein University, a college ranked at 429 has less diversity, but has demographics very similar to the surrounding county of Delaware, Ohio.\n",
    "\n",
    "We are therefore interested in looking at whether ranking is correlated with not only how diverse racial demographics of a campus are, but also how that spread compares with the surrounding city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: Is there a relationship between the ranking tier (top, middle, bottom) and the similarity between the college and surrounding county demographics?\n",
    "\n",
    "#### Hypothesis: Top-ranked universities tend to be magnet schools and pull students from all over the nation. Also, in our experience, there is more pressure for top-ranked schools to be racially diverse, whereas counties don't often have racial demographics split equally. Hence, our intuition is that their demographics will not match the counties. Lower-ranked universities often have local students. We hypothesize that lower ranked schools will have higher racial demographic similarity with the surrounding county. \n",
    "\n",
    "#### Summary: To answer this question, we create a \"diversity metric\", a single value for each college or county, to compare. We do this for the top 3 (1-3), middle 3 (429-431), and bottom 3 (878-880) ranked colleges. \n",
    "\n",
    "#### Limitations: We recognize that 9 datapoints in 3 different categories (\"top\", \"middle\", and \"bottom\") is not enough to create accurate inferences. However, for each county, we need to manually download data. Hence, due to time constraints, we cannot do this analysis with as much data as we would like. We will be cautious of this while making inferences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Before we compare each of the colleges with their counties, we do the analysis for colleges and counties separately.\n",
    "\n",
    "First, we create the dataframe just including the college data for the top 3, middle 3, and bottom 3 colleges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topmidbot = df_800[:3]\n",
    "df_topmidbot = df_topmidbot.append([df_800[428:431], df_800[877:881]])\n",
    "df_topmidbot = df_topmidbot.drop(columns=[\"name\"]) # name is unnecessary information for this analysis\n",
    "df_topmidbot.index = df_topmidbot[\"ranking\"]\n",
    "df_topmidbot.index.names = ['orig_rank']\n",
    "df_topmidbot.ranking = pd.to_numeric(df_topmidbot[\"ranking\"]) #ranking was previously a string value\n",
    "df_topmidbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we must create the \"diversity metric\". We initially tested using the mean as the metric, but for most colleges the metric was .19 or .20. This meant that all of the colleges and counties had the same diversity value, which is clearly not the case, as seen in Graph 1. Hence, we decided to use the variance for each college row as the metric because the value gives more information about dispersion of the racial demographics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topmidbot[\"var\"] =  df_topmidbot.loc[:, [\"African American\", \"Asian\", \"Hispanic\",\"Multiracial\",\"White\"]].var(axis=1)\n",
    "df_topmidbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# College Data\n",
    "# To get \"top\", \"middle\", \"bottom\" categories, change ranking to values of 0-2.\n",
    "df_topmidbot.ranking.loc[(df_topmidbot['ranking'] < 4)] = 0\n",
    "df_topmidbot.ranking.loc[(df_topmidbot['ranking'] >= 4) & (df_topmidbot['ranking'] < 432)] = 1\n",
    "df_topmidbot.ranking.loc[(df_topmidbot['ranking'] > 877)] = 2\n",
    "# County data\n",
    "#remove Alameda, which is used for exploratory phase, and is not needed for Analysis 1\n",
    "df_topmidbot_county = df_counties.drop(\"alameda-ca\")\n",
    "df_topmidbot_county[\"ranking\"] = [0,0,0,1,1,1,2,2,2]\n",
    "df_topmidbot_county = df_topmidbot_county.copy(deep=True)\n",
    "df_topmidbot_county[\"var\"] =  df_topmidbot_county.loc[:, [\"African American\", \"Asian\", \"Hispanic\",\"Multiracial\",\"White\"]].var(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2 = df_topmidbot.boxplot(by ='ranking',column =['var'], grid = False) \n",
    "plt.plot(df_topmidbot[\"ranking\"]+1, df_topmidbot[\"var\"],'r.',alpha=1,marker='o')\n",
    "plt.suptitle(\"Graph 2: Colleges\", fontsize = 14)\n",
    "plt.title(\"\")\n",
    "plt.xticks([1, 2, 3], ['Top', 'Middle', 'Bottom'])\n",
    "graph2.set_ylabel('Diversity Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph suggests 3 things:\n",
    "1. top colleges have low dispersion, and hence have more equal proportions for various races. \n",
    "2. as ranking increases, there is more variability in diversity between colleges of similar rankings.\n",
    "3. While there is an overall increase in the diversity metric, there does not seem to be a linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph3 = df_topmidbot_county.boxplot(by ='ranking', column =['var'], grid = False) \n",
    "plt.plot(df_topmidbot_county[\"ranking\"]+1, df_topmidbot_county[\"var\"],'r.',alpha=1,marker='o')\n",
    "plt.xticks([1, 2, 3], ['Top', 'Middle', 'Bottom'])\n",
    "plt.suptitle(\"Graph 3: Counties of Colleges\", fontsize = 14)\n",
    "plt.title(\"\")\n",
    "graph3.set_ylabel('Diversity Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph suggests 3 things:\n",
    "1. There is a similar trend in the diversity metric means as in graph 2. The trend of variability is not consistent; however, the counties of the bottom ranked category also have the highest variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compare each of the colleges with their counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topmidbot_county = df_topmidbot_county.set_index(\"ranking\") # set index so same as df_topmidbot_county index\n",
    "df_summary = df_topmidbot_county[\"var\"].sub(df_topmidbot[\"var\"], axis = 0).to_frame() \n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph4 = df_summary.boxplot(by ='ranking', column =['var'], widths = 0.6,grid = False)\n",
    "plt.suptitle(\"Graph 4: College and County Demographic Differences by Ranking\")\n",
    "plt.title(\"\")\n",
    "plt.plot(df_summary.index+1, df_summary[\"var\"],'r.',alpha=1,marker='o')\n",
    "plt.xticks([1, 2, 3], ['Top', 'Middle', 'Bottom'])\n",
    "graph4.set_ylabel('Difference between College and County Diversity Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph suggests that there is in fact a slight correlation. As the ranking decreases, the diversity metric of colleges and their surrounding county also decreases somewhat. The correlation seems weak, but we will do a linear regression analysis to determine the extent of this correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var_summary = pd.DataFrame(columns = ['county', 'college']) \n",
    "df_var_summary['college'] = df_topmidbot.loc[df_topmidbot[\"ranking\"] == 0]['var'].values\n",
    "df_var_summary['county'] = df_topmidbot_county['var'].values[:3]\n",
    "\n",
    "outcome, predictors = patsy.dmatrices('college ~ county', df_var_summary)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var_summary['college'] = df_topmidbot.loc[df_topmidbot[\"ranking\"] == 1]['var'].values\n",
    "df_var_summary['county'] = df_topmidbot_county['var'].values[3:6]\n",
    "\n",
    "outcome, predictors = patsy.dmatrices('college ~ county', df_var_summary)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var_summary['college'] = df_topmidbot.loc[df_topmidbot[\"ranking\"] == 2]['var'].values\n",
    "df_var_summary['county'] = df_topmidbot_county['var'].values[6:9]\n",
    "\n",
    "outcome, predictors = patsy.dmatrices('college ~ county', df_var_summary)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the OLS regression results above, the p values of the parameter, county, is always greater than our alpha significance level (0.01), meaning that there no significant difference. Thus, we will not reject the null hypothesis. However, the p value does decrease from top level colleges/cities to mid and bottom level colleges/cities indicating that there is more correlation between mid and bottom level colleges/cities than between top level colleges/cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2\n",
    "\n",
    "## For the second part of the analysis, we're looking to see if we can find a correlation between the racial diversity of a university vs. its undergraduate population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "#get racial demographic data\n",
    "\n",
    "df_niche = pd.read_csv(\"datasets/niche4yearpublicprivate.csv\")\n",
    "\n",
    "#niche[niche.isnull().any(axis=1)]\n",
    "df_columns = df_niche[['African American', 'Asian', 'Hispanic', 'International', 'Multiracial', 'Native American','Pacific Islander', 'Unknown', 'White']]\n",
    "df_niche = df_niche.drop(\"International\", axis=1)\n",
    "for indexr, university in df_niche.iterrows():\n",
    "    sum = 0\n",
    "    for indexc, newvalue in university.iteritems():\n",
    "        if \"%\" in str(newvalue):\n",
    "            oldvalue = (newvalue)\n",
    "            newvalue = (float(newvalue.rstrip(\"%\"))) / 100\n",
    "            df_niche.loc[indexr,indexc] = newvalue\n",
    "            sum = sum + newvalue\n",
    "    for indexc, newvalue in university.iteritems():\n",
    "        if isinstance(df_niche.loc[indexr,indexc], float):\n",
    "            df_niche.loc[indexr,indexc] = round((float(df_niche.loc[indexr,indexc]) / sum),2)\n",
    "\n",
    "df_niche_800 = df_niche\n",
    "df_niche = df_niche.head(500) #top 500 colleges\n",
    "df_niche_800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get undergraduate size data\n",
    "df_niche_pop = pd.read_csv(\"datasets/undergradpop.csv\")\n",
    "for indexr, university in df_niche_pop.iterrows():\n",
    "    newvalue = int(university[2])\n",
    "    df_niche_pop.loc[indexr,\"undergradpop\"] = newvalue\n",
    "df_niche_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all racial demographic, undergraduate population info for top 500 universities (4 year public and private)\n",
    "df_top500 = pd.concat([df_niche, df_niche_pop.undergradpop], axis=1)\n",
    "df_top500 = df_top500[['ranking','name','undergradpop','African American', 'Asian', 'Hispanic', 'Multiracial', 'Native American','Pacific Islander', 'Unknown', 'White']]\n",
    "df_top500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: Can university size/undergraduate population predict the diversity of a student body? \n",
    "\n",
    "#### Hypothesis: Larger unviersities represent a more diverse student body compared to smaller universities. We predict the top tier of undergraduate population are more diverse because bigger universities pull more student applications and therefore are exposed to a more pool of potential students. \n",
    "\n",
    "#### Summary: To answer this question, we create a \"diversity score\", a single value for each college to compare. We do this for each university and after sorting universities into the top third, middle third, and bottom third based on population, this score helps us determine if there is a trend in our data.\n",
    "\n",
    "#### Limitations: We recognize that we have a skewed sample in which we are exposed to more data from smaller schools than larger schools. There are also two categories, 'unknown' and 'bi-racial', that keeps us from seeing a \"true\" measurement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we concatenated everything into one dataframe, we thought a good first step would be to scatter plot the data: each individual proportion vs. the colleges population. We realized after doing so that this data visualization didnt help us much. Below is an example of a scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_top500.undergradpop, df_top500[\"Native American\"])\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Proportion of Race')\n",
    "plt.title('Native American Representation in Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to try to see a clearer correlation with our data, we thought to represent the dataframe with a line graph. We first sorted the dataframe based on undergraduate population and then graphed each separate racial demographic with its respective college size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_top500.sort_values(by=['undergradpop'])\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_sorted.undergradpop, df_top500[\"White\"])\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Proportion of Race')\n",
    "plt.title('White Representation in Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_sorted.undergradpop, df_top500[\"Asian\"])\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Proportion of Race')\n",
    "plt.title('Asian Representation in Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_sorted.undergradpop, df_top500[\"African American\"])\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Proportion of Race')\n",
    "plt.title('African American Representation in Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_sorted.undergradpop, df_top500[\"Hispanic\"])\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Proportion of Race')\n",
    "plt.title('Hispanic Representation in Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_sorted.undergradpop, df_top500[\"Native American\"])\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Proportion of Race')\n",
    "plt.title('Native American Representation in Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_sorted.undergradpop, df_top500[\"Pacific Islander\"])\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Proportion of Race')\n",
    "plt.title('Pacific Islander Representation in Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these graphs, we recorded each pearson correlation coefficient to get a quantitative representation of how this data looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, norm, bernoulli, poisson, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pearsons correlation coefficient = %.3f (p=%.3f)' % (pearsonr(df_sorted['undergradpop'], df_sorted['Asian'])[0], pearsonr(df_sorted['undergradpop'], df_sorted['Asian'])[1]))\n",
    "print('Pearsons correlation coefficient = %.3f (p=%.3f)' % (pearsonr(df_sorted['undergradpop'], df_sorted['African American'])[0], pearsonr(df_sorted['undergradpop'], df_sorted['African American'])[1]))\n",
    "print('Pearsons correlation coefficient = %.3f (p=%.3f)' % (pearsonr(df_sorted['undergradpop'], df_sorted['Hispanic'])[0], pearsonr(df_sorted['undergradpop'], df_sorted['Hispanic'])[1]))\n",
    "print('Pearsons correlation coefficient = %.3f (p=%.3f)' % (pearsonr(df_sorted['undergradpop'], df_sorted['Native American'])[0], pearsonr(df_sorted['undergradpop'], df_sorted['Native American'])[1]))\n",
    "print('Pearsons correlation coefficient = %.3f (p=%.3f)' % (pearsonr(df_sorted['undergradpop'], df_sorted['Pacific Islander'])[0], pearsonr(df_sorted['undergradpop'], df_sorted['Pacific Islander'])[1]))\n",
    "print('Pearsons correlation coefficient = %.3f (p=%.3f)' % (pearsonr(df_sorted['undergradpop'], df_sorted['White'])[0], pearsonr(df_sorted['undergradpop'], df_sorted['White'])[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance: In order to create a quantitative score for diversity, we calculated the variance of every school using the values per racial demographic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top500spread = df_top500[[\"African American\",\"Asian\",\"Hispanic\",\"Native American\",\"Pacific Islander\",\"White\"]]\n",
    "df_top500[\"Majority\"] = df_top500spread.max(axis=1)\n",
    "count = 0\n",
    "for i,j in df_top500.iterrows():\n",
    "    if j['African American'] == j['Majority']:\n",
    "        df_top500.at[i, 'African American'] = 0 \n",
    "    if j['Asian'] == j['Majority']:\n",
    "        df_top500.at[i, 'Asian'] = 0 \n",
    "    if j['Hispanic'] == j['Majority']:\n",
    "        df_top500.at[i, 'Hispanic'] = 0 \n",
    "    if j['Native American'] == j['Majority']:\n",
    "        df_top500.at[i, 'Native American'] = 0 \n",
    "    if j['Pacific Islander'] == j['Majority']:\n",
    "        df_top500.at[i, 'Pacific Islander'] = 0 \n",
    "    if j['White'] == j['Majority']:\n",
    "        df_top500.at[i, 'White'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top500[\"var\"] =  df_top500.loc[:, [\"African American\", \"Asian\", \"Hispanic\",\"Multiracial\",\"Pacific Islander\", \"Native American\", \"Unknown\", \"White\"]].var(axis=1)\n",
    "df_top500[\"mean\"] = df_top500.loc[:, [\"African American\", \"Asian\", \"Hispanic\",\"Multiracial\",\"Pacific Islander\", \"Native American\", \"Unknown\", \"White\"]].mean(axis=1)\n",
    "df_sorted = df_top500.sort_values(by=['undergradpop'])\n",
    "df_top500['Diversity'] = 1-(df_sorted['Majority'] - df_sorted['mean'])\n",
    "df_top500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher variance --> less diverse student body:\n",
    "Here, we are sorting the colleges based upon their undergraduate population/enrollment. We have them split evenly due to the fact that we have a disproportionate amount of larger colleges vs smaller, and so it would provide less accurate results because there is more data being analyzed for some groups than others.\n",
    "We create three new dataframes so we can analyze the top third, middle third, and bottom third of college populations from the 500 top ranked universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top500 = df_top500.sort_values(by = 'undergradpop')\n",
    "df_top500\n",
    "df_split = np.array_split(df_top500, 3)\n",
    "df_top = pd.DataFrame(df_split[0])\n",
    "df_mid = pd.DataFrame(df_split[1])\n",
    "df_bot = pd.DataFrame(df_split[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_top.undergradpop, df_top['Diversity'], c = 'green')\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Diversity Score')\n",
    "plt.title('Bottom Third of Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_mid.undergradpop, df_mid['Diversity'], c = 'green')\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Diversity Score')\n",
    "plt.title('Middle Tier of Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_bot.undergradpop, df_bot['Diversity'], c = 'green')\n",
    "plt.xlabel('School Population')\n",
    "plt.ylabel('Diversity Score')\n",
    "plt.title('Top Tier of Top 500 Universities', fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recorded diversity through the above scatter plots and concluded that there is not an easily identifiable trend from dividing each school population into three groups. From here we ran a test in order to see if there is an un-identified trend between diversity and population that we could not see through the scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('undergradpop ~ Diversity', df_top)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('undergradpop ~ Diversity', df_mid)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('undergradpop ~ Diversity', df_bot)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this test we can see that there is like no correlation between diversity and school size because the coefficient is small (Almost no rise in trend or fall in trend). The p-value is also above 0.01 and our r-value is close to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we wanted to compare the largest, smallest, and medium sized colleges based on their diversity rating. We split these three groups and made a boxplot for each group. Through this we can see very little difference in diversity score based on college population but a little higher variance in the small colleges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1 = df_top.assign(Size=1)\n",
    "data2 = df_mid.assign(Size=2)\n",
    "data3 = df_bot.assign(Size=3)\n",
    "cdf = pd.concat([data1,data2,data3])\n",
    "#mdf = pd.melt(cdf, id_vars=['Size'], var_name=['var'])\n",
    "boxy = cdf.boxplot(by ='Size', column =['Diversity'], grid = False,patch_artist = True)\n",
    "plt.xticks([1, 2, 3], ['Large', 'Medium', 'Small'])\n",
    "plt.suptitle(\"Boxplot 1: Undergraduate Populations\", fontsize = 14)\n",
    "plt.title(\"\")\n",
    "boxy.set_ylabel('Diversity Metric')\n",
    "colors = ['lightblue', 'lightgreen', 'pink']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources\n",
    "The data involving higher education-specific demographics was posted on Niche for anyone to view. We were required to contact Niche for specific permission to use/analyze their data for academic purposes. Niche found its statistics from various official public sources including the FBI, the U.S. Census, and the Department of Education. The data from Niche provides us the racial demographics of the student bodies of 810 4-year colleges and universities in the United States. Categories include: African American, Asian, Hispanic, International, Multiracial, Native American, Pacific Islander, Unknown, White. Our analysis might not prefer the categories of ‘Multiracial’ and ‘Unknown’ since these categories can add noise to our final result and do not give us insight into any specific race. There is also a concern for the category ‘White’, because this can represent both Europeans and Middle Easterns, which racially are equivalent but are societally seen as separate. Niche’s data does not include the number of students enrolled nor any information about any one student.\n",
    "\n",
    "We also utilize city data from the 2010 U.S. Census, looking at city specific racial demographics for cities with populations over 5,000 people: White, Black/African American, American Indian/Alaska Native, Asian, Native Hawaiian/Other Pacific Islander, Two or More Races, Hispanic/Latino. The discrepancy between our data sources’ categories are ‘International’ and ‘Unknown’, which are specific to Niche’s data. Since we do not look into anything more specific than percentages within colleges and cities, we do not invade the personal privacy of our subjects. Aside from what has already been mentioned, we do not anticipate any other issues related to privacy and equitable impact due to the public nature of this dataset (people are aware that their demographics are recorded in college admissions as well as on the U.S. Census).\n",
    "\n",
    "### Analysis / Post Analysis\n",
    "The main concern with this data science question is that the results could potentially be used for implementation of racial quotas in universities. If the analysis is not interpreted properly, the results could be used to support policies that move away from merit-based acceptances. \n",
    "In post-analysis, our results show that there is no strong relationship. However, we recognize that we had many limitations in our analysis process, so we have a limited analysis with low ecological validity that should not be applied to real-world policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first analysis, we sought to find out if the racial demographic of universities was statistically different from their surrounding counties. In the start of our analysis we hypothesized that universities would have a lower diversity ranking than the county they are in. Unfortunately, our analysis did not show this trend and therefore we failed to reject the null hypothesis. From the tests we produced, we did manage to find a small trend based on the p-value decreasing from the top level of colleges/cities to middle and bottom level colleges/cities. Thus, there is possibly a correlation between the middle and bottom level colleges as opposed to the top ranking colleges/cities. With our lack of overall correlation, we realize that our results may be due to eliminating categories of data such as “international” students, which could impact our data. \n",
    "\n",
    "For our second analysis regarding whether or not there is a correlation between racial diversity of a university and the size of the university's population, we concluded that there is no statistically significant correlation with the data we worked with. At first, we thought that there would be a slight correlation between the universities that have a larger population and the rank of diversity in their student body. It was our assumption that schools with a larger population receive a larger quantity and therefore larger variety of applications as well. That being said, our analysis did not show this trend or any type of relationship, even when we conducted multiple tests, making us fail to reject the null hypothesis. Though, our research has shown to have no correlation between these two factors, it may be because of confounding variables within our data. For example, our data set included “bi-racial” and “multiracial” categories, which we did not analyze because of the lack of clarity given for each of these sets. \n",
    "\n",
    "Our previously stated limitations likely caused a larger impact than we previously predicted. Simply looking at the US Census, we can see a national trend of changing proportions of ethnicities. We understood that with a more detailed census, we would have been able to calculate a more accurate representation of our racial proportions. It is likely that the particular age range (18-24 years old) in which we were doing our analysis has different proportions than the age range we worked with. In a future attempt, the best way to do a serious analysis of this data would be to limit the age range in the general population of the cities and the counties. This would focus our data and would hopefully produce a clearer picture of racial proportions in these areas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
