{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data on cities and counties were sourced from https://www.census.gov/quickfacts.\n",
    "\n",
    "Because we will be analyzing the impact, if any, of variously ranked colleges on the respective cities and counties they are located in, we want the data to be organized based on ranking, allowing us to easily isolate the analysis.\n",
    "\n",
    "The U.S. Census Bureau provides us tables with the following data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_dataset_path = './datasets/cities/'\n",
    "counties_dataset_path = './datasets/counties/'\n",
    "\n",
    "# create separate dictionaries for each category of colleges that the cities are home to\n",
    "top_cities = dict()\n",
    "mid_cities = dict()\n",
    "bot_cities = dict()\n",
    "other_cities = dict() # misc areas for further analysis\n",
    "\n",
    "# populate dicts based on filename indicators\n",
    "for c in os.listdir(cities_dataset_path):\n",
    "    # filenames truncated to city-state format for simplicity\n",
    "    truncated_file_name = '-'.join((c.split('-')[:2]))\n",
    "    if c.endswith(\"top-city.csv\"):\n",
    "        top_cities[truncated_file_name] = pd.read_csv(cities_dataset_path + c)\n",
    "    elif c.endswith(\"mid-city.csv\"):\n",
    "        mid_cities[truncated_file_name] = pd.read_csv(cities_dataset_path + c)\n",
    "    elif c.endswith(\"bot-city.csv\"):\n",
    "        bot_cities[truncated_file_name] = pd.read_csv(cities_dataset_path + c)\n",
    "    elif '-' in c:\n",
    "        other_cities[truncated_file_name] = pd.read_csv(cities_dataset_path + c)\n",
    "\n",
    "# similar process for counties\n",
    "top_counties = dict()\n",
    "mid_counties = dict()\n",
    "bot_counties = dict()\n",
    "other_counties = dict()\n",
    "\n",
    "for c in os.listdir(counties_dataset_path):\n",
    "    # filenames truncated to county-state format for simplicity\n",
    "    truncated_file_name = '-'.join((c.split('-')[:2]))\n",
    "    if c.endswith(\"top-county.csv\"):\n",
    "        top_counties[truncated_file_name] = pd.read_csv(counties_dataset_path + c)\n",
    "    elif c.endswith(\"mid-county.csv\"):\n",
    "        mid_counties[truncated_file_name] = pd.read_csv(counties_dataset_path + c)\n",
    "    elif c.endswith(\"bot-county.csv\"):\n",
    "        bot_counties[truncated_file_name] = pd.read_csv(counties_dataset_path + c)\n",
    "    elif '-' in c:\n",
    "        other_counties[truncated_file_name] = pd.read_csv(counties_dataset_path + c)\n",
    "\n",
    "# testing\n",
    "print('============== TOP TEST ===============')\n",
    "print(top_cities['stanford-ca'])\n",
    "print('\\n============== MID TEST ===============')\n",
    "print(mid_cities['whitewater-wi'])\n",
    "print('\\n============== BOT TEST ===============')\n",
    "print(bot_counties['westmoreland-pa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the data we wanted to clean was simply the name of the column that holds all the statistic values. The name was originally just the name of the county/city. We believe that changing it to \"fact_value\" (given that the column with the name of the statistic is \"fact\", would be more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv = [top_cities, mid_cities, bot_cities, other_cities, top_counties, mid_counties, bot_counties, other_counties]\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        v.rename(index = str, columns = {v.columns[2] : 'Fact Value'}, inplace = True)\n",
    "\n",
    "assert top_cities['cambridge-ma'].columns[2] == 'Fact Value'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the column that should hold the fact value is of type object (str). We want this to be converted to ints so that we do not need to constantly type cast when performing our analysis.\n",
    "\n",
    "To do this, we need to first delete rows that a fact value that indicates this statistic is not useful such as NA for not available. Further descriptions of the invalid value strings are given in a following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(bot_cities['redding-ca'].loc[bot_cities['redding-ca']['Fact Value'] == 'X']) != 0\n",
    "invalid_values = ['X', 'NA', 'D', '-', 'FN', 'F', 'S', 'Z']\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        for i, r in v.iterrows():\n",
    "            if r['Fact Value'] in invalid_values:\n",
    "                v.drop(i, inplace = True)\n",
    "                \n",
    "\n",
    "assert len(bot_cities['redding-ca'].loc[bot_cities['redding-ca']['Fact Value'] == 'X']) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can iterate through the Fact Value column, strip all non-numeric or . (indicating a decimal number) characters and retype each value from str to float64. We print out the pre and post cleaning types of the Fact Value column to verify our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before cleaning:')\n",
    "print(mid_counties['walworth-wi']['Fact Value'].dtypes)\n",
    "\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        v.loc[:, 'Fact Value'] = v.loc[:, 'Fact Value'].str.strip('%\"$')\n",
    "        v.loc[:, 'Fact Value'] = v.loc[:, 'Fact Value'].str.replace(',', '')   \n",
    "        v.loc[:, 'Fact Value'] = v.loc[:, 'Fact Value'].astype('float64')\n",
    "        \n",
    "print('\\nAfter cleaning:')\n",
    "print(mid_counties['walworth-wi']['Fact Value'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the initial output of our data wrangling, there are a couple of entirely or largely unneeded *columns* in the data where all the values are either NaN or irrelevant. \n",
    "\n",
    "We will be dropping or modifying the following columns to clean the data:\n",
    "\n",
    "###### Fact Note:\n",
    "\n",
    "This indicates:\n",
    "\n",
    "**(a)** Includes persons reporting only one race\n",
    "\n",
    "**(b)** Hispanics may be of any race, so also are included in applicable race categories\n",
    "\n",
    "**(c)** Economic Census - Puerto Rico data are not comparable to U.S. Economic Census Data\n",
    "\n",
    "As none of these factors influence the demographic data of the areas we are analyzing, we can remove this data.\n",
    "\n",
    "###### Value Note \n",
    "\n",
    "This indicates: \n",
    "\n",
    "**(-)** Either no or too few sample observations were available to compute an estimate, or a ratio of medians cannot be calculated because one or both of the median estimates falls in the lowest or upper interval of an open ended distribution.\t\n",
    "\n",
    "**(D)**\tSuppressed to avoid disclosure of confidential information\t\n",
    "\n",
    "**(F)**\tFewer than 25 firms\t\t\n",
    "\n",
    "**(FN)** Footnote on this item in place of data\t\n",
    "\n",
    "**(NA)** Not available\t\t\n",
    "\n",
    "**(S)**\tSuppressed; does not meet publication standards\n",
    "\n",
    "**(X)**\tNot applicable\n",
    "\n",
    "**(Z)**\tValue greater than zero but less than half unit of measure shown\n",
    "\n",
    "Value notes are indicated in the Fact Value column so we do not need the Value Note column at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert top_cities['stanford-ca'].shape == (67, 4)\n",
    "\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        v.drop([v.columns[1], v.columns[3]], axis = 1, inplace = True)\n",
    "\n",
    "assert top_cities['stanford-ca'].shape == (67, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also observe that there are also many *rows* that have a NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        print('NaN values in each column for ' + k + ':\\n'+ str(v.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These NaN rows are not useful, so we will drop these rows entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        v.dropna(inplace = True)\n",
    "        print('NaN values in each column for ' + k + ':\\n'+ str(v.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our analysis will only need statistics about demographics, we can drop all rows with irrelevant statistics. We decided to do this last so that, in case we do need to use other statistics, the data for that row will already be cleaned up to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_rows = ['White alone, percent', 'Black or African American alone, percent', 'American Indian and Alaska Native alone, percent', 'Asian alone, percent', 'Native Hawaiian and Other Pacific Islander alone, percent', 'Two or More Races, percent', 'Hispanic or Latino, percent', 'White alone, not Hispanic or Latino, percent']\n",
    "\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        d[k] = v.loc[(v['Fact'].isin(demographic_rows))]\n",
    "        # reset index to start from 0 since rows before may have been dropped\n",
    "        d[k].reset_index(drop = True, inplace = True)\n",
    "\n",
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        assert d[k].shape == (7, 2) or d[k].shape == (8, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now left with dataframes that are of shape either (7, 2) or (8, 2), have no NaN values, have values that are ready to analyze and work with (float type) and only contain relevant demographic statistics.\n",
    "\n",
    "#### Here is the final cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in all_csv:\n",
    "    for k, v in d.items():\n",
    "        print(k + ' | shape: ' + str(v.shape))\n",
    "        print(v)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's convert the data from dictionaries to dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder cities dictionaries to correspond with rankings\n",
    "\n",
    "order_top_cities = OrderedDict()\n",
    "order_top_cities['cambridge-ma'] = top_cities['cambridge-ma']\n",
    "order_top_cities['stanford-ca'] = top_cities['stanford-ca']\n",
    "order_top_cities['newhaven-ct'] = top_cities['newhaven-ct']\n",
    "top_cities = order_top_cities\n",
    "\n",
    "order_mid_cities = OrderedDict()\n",
    "order_mid_cities['westerville-oh'] = mid_cities['westerville-oh']\n",
    "order_mid_cities['whitewater-wi'] = mid_cities['whitewater-wi']\n",
    "order_mid_cities['jacksonville-il'] = mid_cities['jacksonville-il']\n",
    "mid_cities = order_mid_cities\n",
    "\n",
    "order_bot_cities = OrderedDict()\n",
    "order_bot_cities['greensburg-pa'] = bot_cities['greensburg-pa']\n",
    "order_bot_cities['sanbernardino-ca'] = bot_cities['sanbernardino-ca']\n",
    "order_bot_cities['redding-ca'] = bot_cities['redding-ca']\n",
    "bot_cities = order_bot_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all city csv to dataframe\n",
    "columns = demographic_rows\n",
    "\n",
    "df_cities = pd.DataFrame()\n",
    "i1 = 0\n",
    "city_csv = [top_cities, mid_cities, bot_cities, other_cities]\n",
    "for a in city_csv:\n",
    "    index = 0\n",
    "    for b in a.keys():\n",
    "        i2 = 0\n",
    "        for x in range(0, 8):\n",
    "            if x < len(city_csv[i1].get(b)[\"Fact Value\"]):\n",
    "                #if a value is not present (always pacific islander data), we set it equal to zero\n",
    "                if (len(city_csv[i1].get(b)[\"Fact Value\"]) < 7) and x ==4:\n",
    "                     df_cities.loc[x,b] = 0\n",
    "                else:\n",
    "                    df_cities.loc[x,b] = (city_csv[i1].get(b)[\"Fact Value\"][i2])\n",
    "            i2 = i2 + 1\n",
    "    i1 = i1 + 1\n",
    "    index = index + 1\n",
    "df_cities = df_cities.transpose()\n",
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder county dictionaries to correspond with rankings\n",
    "\n",
    "order_top_counties = OrderedDict()\n",
    "order_top_counties['middlesex-ma'] = top_counties['middlesex-ma']\n",
    "order_top_counties['santaclara-ca'] = top_counties['santaclara-ca']\n",
    "order_top_counties['newhaven-ct'] = top_counties['newhaven-ct']\n",
    "top_counties = order_top_counties\n",
    "\n",
    "order_mid_counties = OrderedDict()\n",
    "order_mid_counties['delaware-oh'] = mid_counties['delaware-oh']\n",
    "order_mid_counties['walworth-wi'] = mid_counties['walworth-wi']\n",
    "order_mid_counties['morgan-il'] = mid_counties['morgan-il']\n",
    "mid_counties = order_mid_counties\n",
    "\n",
    "order_bot_counties = OrderedDict()\n",
    "order_bot_counties['westmoreland-pa'] = bot_counties['westmoreland-pa']\n",
    "order_bot_counties['sanbernardino-ca'] = bot_counties['sanbernardino-ca']\n",
    "order_bot_counties['shasta-ca'] = bot_counties['shasta-ca']\n",
    "bot_counties = order_bot_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all county csv to dataframe\n",
    "df_counties = pd.DataFrame()\n",
    "i1 = 0\n",
    "county_csv = [top_counties, mid_counties, bot_counties, other_counties]\n",
    "for a in county_csv:\n",
    "    index = 0\n",
    "    for b in a.keys():\n",
    "        bool = False\n",
    "        i2 = 0\n",
    "        for x in range(0, 8):\n",
    "            if len(county_csv[i1].get(b)[\"Fact Value\"]) < 8 and x==4:\n",
    "                bool = True\n",
    "                df_counties.loc[x,b] = 0\n",
    "            elif bool == True:\n",
    "                df_counties.loc[x,b] = (county_csv[i1].get(b)[\"Fact Value\"][i2-1])\n",
    "            else:\n",
    "                df_counties.loc[x,b] = (county_csv[i1].get(b)[\"Fact Value\"][i2])\n",
    "            i2 = i2 + 1\n",
    "    i1 = i1 + 1\n",
    "    index = index + 1\n",
    "df_counties = df_counties.transpose()\n",
    "df_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indexr, city in df_cities.iterrows():\n",
    "    for indexc, newvalue in city.iteritems():\n",
    "        if \".\" in str(newvalue):\n",
    "            oldvalue = (newvalue)\n",
    "            newvalue = (float(newvalue)) / 100\n",
    "            df_cities.loc[indexr,indexc] = round(newvalue, 2)\n",
    "\n",
    "df_cities.columns = [\"White all\", \"African American\", \"Native American\", \"Asian\", \"Pacific Islander\", \"Multiracial\", \"Hispanic\", \"White\"]\n",
    "df_cities['Unknown'] = 1 - df_cities[\"White\"] - df_cities[\"African American\"]-df_cities[\"Native American\"] -df_cities[\"Asian\"]-df_cities[\"Pacific Islander\"] -df_cities[\"Multiracial\"]\n",
    "df_cities = df_cities.drop(\"White all\", axis=1)\n",
    "\n",
    "cols = ['African American', 'Asian', 'Hispanic', 'Multiracial',\n",
    "       'Native American', 'Pacific Islander', 'Unknown', 'White']\n",
    "df_cities = df_cities[cols]\n",
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indexr, county in df_counties.iterrows():\n",
    "    for indexc, newvalue in county.iteritems():\n",
    "        if \".\" in str(newvalue):\n",
    "            oldvalue = (newvalue)\n",
    "            newvalue = (float(newvalue)) / 100\n",
    "            df_counties.loc[indexr,indexc] = round(newvalue, 2)\n",
    "\n",
    "df_counties.columns = [\"White all\", \"African American\", \"Native American\", \"Asian\", \"Pacific Islander\", \"Multiracial\", \"Hispanic\", \"White\"]\n",
    "df_counties['Unknown'] = 1 - df_counties[\"White\"] - df_counties[\"African American\"]-df_counties[\"Native American\"] -df_counties[\"Asian\"]-df_counties[\"Pacific Islander\"] -df_counties[\"Multiracial\"]\n",
    "df_counties = df_counties.drop(\"White all\", axis=1)\n",
    "cols = ['African American', 'Asian', 'Hispanic', 'Multiracial',\n",
    "       'Native American', 'Pacific Islander', 'Unknown', 'White']\n",
    "df_counties = df_counties[cols]\n",
    "df_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
